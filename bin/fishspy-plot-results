#!/usr/bin/python3

import os
import sys
import json
import csv
import math
import numpy as np
import scipy.ndimage as nd
import scipy.ndimage.filters
import PIL.Image
import re

pos_bin_cnt = 5

def main(eventcsv, framecsv):

    # gather all environment-passed params up front, so we can print
    # one summary report of effective parameters for this run.

    # use X_SLICE=left:right to crop the X axis... 0:10:1 is full length of average test cycle
    x_slice = [ np.clip(float(s), 0, 1) for s in os.getenv('X_SLICE', '0:1').split(':') ]

    # use X_BINWIDTH=n to collapse n frames into one plot pixel in X axis
    x_reduce = int(os.getenv('X_BINWIDTH', '7')) # 7x reduction appropriate for 20 fps?

    # use FISHSPY_INVALID_BINS to ignore measurement bins
    user_invalid = [ int(x) for x in os.getenv('FISHSPY_INVALID_BINS', '').split(',') if x ]

    # use FISHSPY_US_CS_RATIO to force US period when not detected by light levels
    us_cs_ratio = float(os.getenv('FISHSPY_US_CS_RATIO', '0.2'))

    # use FISHSPY_FPS to override presumed framerate
    fps = int(os.getenv('FISHSPY_FPS', '20'))

    # use FISHSPY_TRIAL_COUNTS to force experiment phases when not detected by light levels
    try:
        trial_counts = os.getenv('FISHSPY_TRIAL_COUNTS')
        trial_counts = trial_counts.split(',')
    except:
        trial_counts = None

    if trial_counts is not None:
        assert len(trial_counts) == 4, "FISHSPY_TRIAL_COUNTS must be comma-separated list of 4 decimal integers"
        trial_counts = np.array([ int(x) for x in trial_counts ], dtype=np.int32)

    cs_window = [ float(x) for x in os.getenv('FISHSPY_SUM_CSWINDOW', '0:0.10').split(':') ]
    assert(len(cs_window)==2)

    cs_duty_cycle = os.getenv('FISHSPY_SUM_DUTY', 'false').lower() == 'true'

    track_height = int(os.getenv('TRACKHEIGHT', '6'))

    # use FISHSPY_SHOW_RAW to disable raw activity signal for pure binary pulse trains
    show_raw = os.getenv('FISHSPY_SHOW_RAW', 'true').lower() == 'true'

    def get_color(key, default):
        envstr = os.getenv(key, default)
        parts = envstr.split(',')
        parts = [ float(x) for x in parts ]
        if len(parts) > 1:
            return np.array(parts, dtype=np.float32)
        else:
            return parts[0]

    # use different default coloring for raw vs binary viz mode
    if show_raw:
        bg_color = get_color('COLOR_BG', '1,1,1')
        cs_bg_color = get_color('COLOR_CS', '0.9,1,1')
        us_bg_color = get_color('COLOR_US', '0.9,0.75,0.9')
    else:
        bg_color = get_color('COLOR_BG', '1,1,1')
        cs_bg_color = get_color('COLOR_CS', '0.9,0.9,0.9')
        us_bg_color = get_color('COLOR_US', '0.75,0.75,0.75')

    print("""
Effective environment flags:
   X_SLICE=%s
   X_BINWIDTH=%s
   FISHSPY_INVALID_BINS=%s
   FISHSPY_US_CS_RATIO=%s
   FISHSPY_TRIAL_COUNTS=%s
   FISHSPY_SUM_CSWINDOW=%s
   FISHSPY_SUM_DUTY=%s
   FISHSPY_FPS=%s
   TRACKHEIGHT=%s
   FISHSPY_SHOW_RAW=%s
   COLORBG=%s
   COLORUS=%s
   COLORCS=%s
""" % (
    '%s:%s' % (x_slice[0], x_slice[1]),
    '%d' % x_reduce,
    ','.join([ '%d' % x for x in user_invalid ]),
    '%s' % us_cs_ratio,
    ','.join([ '%d' % x for x in trial_counts ]) if trial_counts is not None else '',
    '%s:%s' % (cs_window[0], cs_window[1]),
    str(cs_duty_cycle).lower(),
    '%d' % fps,
    '%d' % track_height,
    str(show_raw).lower(),
    ','.join([ '%s' % x for x in bg_color ]),
    ','.join([ '%s' % x for x in cs_bg_color ]),
    ','.join([ '%s' % x for x in us_bg_color ]),
))

    # extract CS periods as [ (CS_on_frame, US_on_frame or -1, off_frame), ... ]
    CS_periods = []
    
    frameno_idx = None
    comment_idx = None
    t0 = None
    t1 = -1
    t2 = None

    # load up events CSV to get detected CS period frame numbers etc.
    f = open(eventcsv, 'r')
    for row in csv.reader(f):
        if frameno_idx is None:
            frameno_idx = row.index('frameno')
            comment_idx = row.index('comment')
        else:
            comment = row[comment_idx]
            pattern = 'light state='
            pos = comment.find(pattern)
            if pos >= 0:
                state = comment[pos + len(pattern):][0:2]
                if state == 'CS' and t0 is None:
                    t0 = int(row[frameno_idx])
                elif state == 'US' and t1 == -1:
                    if t0 is None:
                        t0 = int(row[frameno_idx])
                    else:
                        t1 = int(row[frameno_idx])
                elif state == 'of':
                    t2 = int(row[frameno_idx])
                    assert t0 < t2
                    assert t1 < t2
                    assert t1 > t0 or t1 == -1, (t0, t1, t2)
                    CS_periods.append( (t0, t1, t2) )
                    t0 = None
                    t1 = -1
                    t2 = None

    if CS_periods:
        CS_periods = np.array(CS_periods, dtype=np.int32)
        CS_cnt = CS_periods.shape[0]
        CS_max_duration = (CS_periods[:,2] - CS_periods[:,0]).max()
        CS_cycles = (CS_periods[1:,0] - CS_periods[0:-1,0])
        print ("%d periods, %d frames max duration, %f average cycle, %d median cycle" % (CS_cnt, CS_max_duration, CS_cycles.mean(), np.median(CS_cycles)))
    else:
        print ("found 0 CS periods... control experiment?")
        CS_periods = None
        CS_cnt = 0
        CS_max_duration = None
        CS_cycles = None

    # extract binned position data into array with shape FxB for F frames and B bins
    frame_bins = []
    frameno_idx = None
    pos_bin_idxs = None
    frameno = -1
    
    for row in csv.reader(open(framecsv, 'r')):
        if frameno_idx is None:
            frameno_idx = row.index('frameno')
            pos_bin_idxs = [ row.index('position bin %d' % i) for i in range(5) ]
        else:
            assert int(row[frameno_idx]) == (frameno + 1), (frameno, row)
            frameno = int(row[frameno_idx])
            frame_bins.append( [ int(row[idx]) for idx in pos_bin_idxs ] )

    frame_bins = np.array(frame_bins, dtype=np.int32)

    print ("%d frames, %d position bins" % frame_bins.shape)
    print ("%d min/%d avg/%d max position spread" % (frame_bins.min(), frame_bins.mean(), frame_bins.max()))

    # zeros in input mean invalid measurements
    invalid = np.zeros(frame_bins.shape, dtype=np.bool)

    invalid = frame_bins == 0
    # invalid status contaminates next frame since we cannot compute differences w/ only one valid number
    invalid[1:,:] += frame_bins[0:-1,:] == 0
    invalid[0,:] = 1

    # get optional invalid mask from user
    if len(user_invalid) < invalid.shape[1]:
        user_invalid.extend([ 0 for x in range(invalid.shape[1] - len(user_invalid)) ])
    elif len(user_invalid) > invalid.shape[1]:
        user_invalid = user_invalid[0:invalid.shape[1]]
    user_invalid = np.array(user_invalid, dtype=np.bool)
    invalid += user_invalid
    user_invalid = user_invalid[None,:]
        
    # characterize statically invalid bins from aggregate TODO: other percentile threshold?
    static_invalid = np.median(invalid[:,:], axis=0).astype(np.bool)[None,:] | user_invalid

    # absolute interframe deltas, filling first frame with zeros
    frame_delta_bins = np.zeros(frame_bins.shape, dtype=np.float32)
    frame_delta_bins[1:,:] = np.abs(frame_bins[1:,:] - frame_bins[0:-1,:])

    # replace invalid with black (no motion)
    frame_delta_bins = np.ma.masked_array(frame_delta_bins, mask=invalid)
    frame_delta_bins = np.ma.filled(frame_delta_bins, fill_value=0.0)

    # replace dynamic invalid with max_value (max motion)
    max_level = frame_delta_bins.max()
    frame_delta_bins = np.ma.masked_array(frame_delta_bins, mask=np.logical_and(invalid, np.invert(static_invalid[:,:])))
    frame_delta_bins = np.ma.filled(frame_delta_bins, fill_value=max_level)

    # use the X percentile tail-speed estimate from k/5 bins at each timestep
    temp = np.percentile(frame_delta_bins, 100. * 4.5/5, axis=1)[:,None]
    # mask out boundaries to de-glitch at global illumination changes
    if CS_periods is not None:
        for period in range(CS_cnt):
            temp[CS_periods[period,0]-1:CS_periods[period,0]+2,:] = 0
            temp[CS_periods[period,1]-1:CS_periods[period,0]+2,:] = 0
            temp[CS_periods[period,2]-1:CS_periods[period,2]+2,:] = 0

    # smear tail-speed over time
    temp = scipy.ndimage.filters.gaussian_filter(temp, sigma=0.4) # size is 6sigma - 1, sigma=1.35->diameter 7.1

    # use log-scale intensity for raw tail speed viz...
    tail_speed = np.log1p(temp)
    tail_speed_range = (tail_speed.min(), tail_speed.max())
    tail_speed = (tail_speed - tail_speed_range[0]) * (1./(tail_speed_range[1] - tail_speed_range[0]))
    print('tail_speed %s %s .. %s' % (tail_speed.dtype, tail_speed.min(), tail_speed.max()))

    # thresholded motion values as boolean
    print('activity range %s .. %s (%s mean)' % (temp.min(), temp.max(), temp.mean()))
    frame_activity = (temp >= (temp.mean() + 0.04 * (temp.max()-temp.mean())  ))

    print ("%d min/%d avg/%d max delta position spread" % (frame_delta_bins.min(), frame_delta_bins.mean(), frame_delta_bins.max()))

    trial_periods = None
    static_trial_phases = False

    # determine analysis and plot space

    if CS_periods is not None:
        # prefer to use detected values if movie events were found
        width = int(np.median(CS_cycles))
        preroll = int((width - CS_max_duration) / 3.0)
        draw_boundaries = True

        trial_periods = np.zeros( (4,), dtype=np.int32 )
        for cs, us, off in CS_periods:
            # HACK: assume valid US detection is at least 1.5 seconds * 20fps after CS detection
            if (us - cs) <= (1.5*fps):
                if trial_periods[2] == trial_periods[1]:
                    trial_periods[1:] += 1
                else:
                    trial_periods[3:] += 1
            else:
                if trial_periods[3] == trial_periods[2]:
                    trial_periods[2:] += 1
        if len(CS_periods) == trial_periods[1]:
            # reset due to lack of detected US periods, i.e. older 2-level illumination movies
            trial_periods = None
        else:
            print ("trial_periods from events: %s" % trial_periods)
    else:
        assert trial_counts is not None, "Must provide FISHSPY_TRIAL_COUNTS for control data lacking CS periods"

        # mock up state to try to plot control data
        CS_cnt = trial_counts.sum()
        width = int(128 * fps)
        preroll = int(width / 3.0)

        # pretend we have uniform zero-width CS periods to fool the plot method
        CS_periods = np.array(
            [
                ( i * width + preroll, -1, i * width + preroll)
                for i in range(CS_cnt)
            ],
            np.int32
        )

        draw_boundaries = False

    if trial_counts is not None and trial_periods is None:
        # use env. supplied trial counts as fallback when detection failed for old or control movies
        trial_periods = np.zeros( (4,), dtype=np.int32 )
        for p in range(1,4):
            trial_periods[p] = trial_counts[0:p].sum()
        static_trial_phases = True
        print ("trial_periods from ENV: %s" % trial_periods)
    elif trial_periods is None:
        # fake CS-only trial periods
        trial_periods = np.zeros( (4,), dtype=np.int32 )
        trial_periods[1:] = len(CS_periods)

    assert width > 1000, "CS interval detection has failed to find a reasonable interval width"

    img = np.full((CS_cnt, track_height, width, 3), bg_color, dtype=np.float32)

    print ("%s plot space" % (img.shape,))

    csv_cycle_rows = [
        ('cycle', 'type', ('cs_window_duty' if cs_duty_cycle else 'cs_window_sum'), 'pre_cs_act', 'post_cs_act', 'pre_us_act', 'post_us_act'),
    ]

    habit_rounds = []
    train_rounds = []
    test_rounds = []
    retrain_rounds = []
    us_boundaries_inferred = 0
    us_boundaries_detected = 0

    period_sums = np.zeros((CS_cnt,), dtype=np.float32)

    # accumulate the data one round at a time, since sub-interval lengths vary per cycle
    for period in range(CS_cnt):

        # one data cycle
        d0 = CS_periods[period, 0] - preroll
        d1 = CS_periods[period + 1, 0] if period < (CS_cnt - 1) else frame_bins.shape[0]
        dw = min(d1 - d0, img.shape[2])
        d1 = d0 + dw
        
        dL = CS_periods[period, 2] - CS_periods[period, 0]

        # figure out offset for preroll and padding if not enough preroll data available
        pad = abs(d0) if d0 < 0 else 0
        d0 += pad
        i0 = pad
        i1 = pad + dw

        # measure cycle activity windows relative to CS on/off boundaries
        wCS = CS_periods[period, 0]
        wUS = CS_periods[period, 1]
        w100 = CS_periods[period, 2]
        ww = w100 - wCS

        wG1 = wCS - int(0.20 * ww)
        w30 = int(0.30 * ww) + wCS
        wG2 = wUS - int(0.20 * ww)
        w130 = int(1.30 * ww) + wCS

        # draw CS period background
        img[period,0:-1,preroll:preroll + dL,:] = cs_bg_color

        # HACK: assume valid US detection is at least 1.5 seconds * 20fps after CS detection
        cycle_type = 'CS'
        if (CS_periods[period, 1] - CS_periods[period, 0]) > (1.5*fps):
            us_boundaries_detected += 1
            # show unconditioned stimulus marker too
            US_offset = CS_periods[period,1] - CS_periods[period,0]
            img[period,0:-1,preroll + US_offset:preroll + dL,:] = us_bg_color
            #
            cycle_type = 'CS+US'
        elif static_trial_phases and ((trial_periods[1] <= period < trial_periods[2]) or (trial_periods[2] < trial_periods[3] <= period)):
            # simulate US detection
            us_boundaries_inferred += 1
            wUS = wCS + int((1.0 - us_cs_ratio) * ww)
            wG2 = wUS - int(0.20 * ww)
            # show unconditioned stimulus marker too
            #
            img[period,0:-1,preroll + int(dL * (1.0 - us_cs_ratio)):preroll + dL,:] = us_bg_color
            #
            cycle_type = 'CS+US'

        if show_raw:
            # HACK: try to mix raw signal with pulse train markers
            tth = int(img.shape[1]//3) # track transition height for inactive/active pulses
            img[period,tth:-1,i0:i1,:] *= (1.0 - tail_speed[d0:d1])
            img[period,0:tth,i0:i1,:] *= (1.0 - tail_speed[d0:d1]) * frame_activity[d0:d1] + np.logical_not(frame_activity[d0:d1])
        else:
            img[period,0:-1,i0:i1,:] *= np.logical_not(frame_activity[d0:d1])

        # convert CS summing window ratios into actual window for this cycle
        cs_window_pix = [ int(d0 + preroll + dL * x) for x in cs_window ]

        # compute window-based measures
        if cs_duty_cycle:
            period_sums[period] = frame_activity[cs_window_pix[0]:cs_window_pix[1]].sum() / (cs_window_pix[1] - cs_window_pix[0])
        else:
            period_sums[period] = (tail_speed[cs_window_pix[0]:cs_window_pix[1]] * frame_activity[cs_window_pix[0]:cs_window_pix[1]]).sum()
        act_pre_cs = np.abs(frame_activity[wG1:wCS,0]).sum() > 0
        act_cs = np.abs(frame_activity[wCS:w30,0]).sum() > 0
        act_pre_us = np.abs(frame_activity[wG2:wUS,0]).sum() > 0
        act_us = np.abs(frame_activity[wUS:w130,0]).sum() > 0

        # accumulate measures we will dump in CSV or JSON reports
        measures = (act_pre_cs, act_cs, act_pre_us, act_us)
        if trial_periods[0] <= period < trial_periods[1]:
            habit_rounds.append( measures )
        elif trial_periods[1] <= period < trial_periods[2]:
            train_rounds.append( measures )
        elif trial_periods[2] <= period < trial_periods[3]:
            test_rounds.append ( measures )
        elif trial_periods[3] <= period:
            retrain_rounds.append( measures )

        csv_cycle_rows.append(
            (period, cycle_type, period_sums[period]) + measures
        )

    print("Trial periods: %s" % (trial_periods))

    # reshape track,bin dimensions into single Y axis for image
    img = img.reshape((CS_cnt * track_height, img.shape[2], 3))
    img_full = img

    print ("%s min/%s avg/%s max plot spread" % (img.min(), img.mean(), img.max()))

    assert (len(x_slice) == 2)
    left_edge = int(np.clip(x_slice[0] * img.shape[1], 0, img.shape[1]-1))
    right_edge = int(np.clip(x_slice[1] * img.shape[1], left_edge+1, img.shape[1]))

    if True:
        # use minimum (darkest) color in each bin
        img = nd.minimum_filter(img_full, size=(1,x_reduce,1))[:,left_edge:right_edge:x_reduce,:]
    else:
        # bin-average the colors
        img = img[:,int(x_reduce*(left_edge//x_reduce)):int(x_reduce*(right_edge//x_reduce)),:]
        for x in range(1,x_reduce):
            img[:,0::x_reduce,:] += img[:,x::x_reduce,:]
        img = (img[:,0::x_reduce,:]/x_reduce)

    print ("Using X_SLICE=%s:%s X_BINWIDTH=%d to reduce X axis" % (x_slice[0], x_slice[1], x_reduce))
    print("Image shape %s reduced and cropped to shape %s" % (img_full.shape, img.shape))

    # convert normalized float into 8-bit RGB
    img *= 255.0 / img[:,:,1].max()
    img = np.clip(img, 0.0, 255.0)

    print ("%s min/%s avg/%s max plot spread" % (img.min(), img.mean(), img.max()))

    m1 = re.match('^(?P<id>[^.]+)[.]events[.]csv(?P<version>:[^:]+)?$', os.path.basename(eventcsv))
    m2 = re.match('^(?P<id>[^.]+)[.]frame_measures[.]csv(?P<version>:[^:]+)?$', os.path.basename(framecsv))
    if m1 and m2 and m1.groupdict().get('id') == m2.groupdict().get('id'):
        png_filename2 = '%s.plot3.png' % m1.groupdict().get('id')
        csv_filename = '%s.sums.csv' % m1.groupdict().get('id')
        json_filename = '%s.grade.json' % m1.groupdict().get('id')
    else:
        # old-style for backward compatibility
        png_filename2 = 'movie_plot3.png'
        csv_filename = 'movie_sums.csv'
        json_filename = 'movie_grade.json'

    PIL.Image.fromarray(img.astype(np.uint8), mode='RGB').save(png_filename2)

    outf = open(csv_filename, 'w')
    writer = csv.writer(outf)
    for row in csv_cycle_rows:
        writer.writerow(row)
    del writer
    outf.close()

    habit_check = habit_rounds[-10:]
    trainA_check = train_rounds
    trainL_check = train_rounds[-len(train_rounds)//2:]
    test_check = test_rounds

    grade = {
        "us_boundaries_detected": us_boundaries_detected,
        "us_boundaries_inferred": us_boundaries_inferred,
        "habituation_denominator": len(habit_check),
        "habituation_cs_numerator": len([ True for g1, a1, g2, a2 in habit_check if a1 ]),
        "habituation_cs_guard_numerator": len([ True for g1, a1, g2, a2 in habit_check if g1 ]),
        "training_all_denominator": len(trainA_check),
        "training_late_denominator": len(trainL_check),
        "training_all_cs_numerator": len([ True for g1, a1, g2, a2 in trainA_check if a1 ]),
        "training_all_us_numerator": len([ True for g1, a1, g2, a2 in trainA_check if a2 ]),
        "training_late_cs_numerator": len([ True for g1, a1, g2, a2 in trainL_check if a1 ]),
        "training_late_us_numerator": len([ True for g1, a1, g2, a2 in trainL_check if a2 ]),
        "testing_denominator": len(test_check),
        "testing_cs_numerator": len([ True for g1, a1, g2, a2 in test_check if a1 ]),
        "testing_cs_guard_numerator": len([ True for g1, a1, g2, a2 in test_check if g1 ]),
    }

    if not grade["training_all_denominator"]:
        aversive = None
    elif not grade["training_late_denominator"]:
        aversive = None
    elif float(grade["training_all_us_numerator"])/grade["training_all_denominator"] >= 0.5 \
         and float(grade["training_late_us_numerator"])/grade["training_late_denominator"] >= 0.5:
        aversive = True
    else:
        aversive = False

    grade.update({
        "habituated": float(grade["habituation_cs_numerator"])/grade["habituation_denominator"] <= 6./20 if grade["habituation_denominator"] else None,
        "aversive": aversive
    })
    if not grade["habituated"]:
        grade["summary"] = "bhv_no_habituation"
    elif not grade["aversive"]:
        grade["summary"] = "bhv_no_aversion"
    elif float(grade["testing_cs_numerator"])/grade["testing_denominator"] >= 4.5/5 if grade["testing_denominator"] else None:
        grade["summary"] = "bhv_learner"
    elif float(grade["testing_cs_numerator"])/grade["testing_denominator"] <= 0.5/5 if grade["testing_denominator"] else None:
        grade["summary"] = "bhv_nonlearner"
    else:
        grade["summary"] = "bhv_inconclusive"

    outf = open(json_filename, 'w')
    print(json.dumps(grade))
    json.dump(grade, outf)
    outf.close()

if __name__ == '__main__':
    events = sys.argv[1]
    frames = sys.argv[2]
    exit(main(events, frames))

