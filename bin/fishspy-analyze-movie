#!/usr/bin/python3

import os
import sys
import subprocess
import json
import csv
import math
import numpy as np
import h5py
import scipy.ndimage as nd
from scipy.ndimage import gaussian_filter, maximum_filter1d, minimum_filter1d
from scipy.misc import toimage
from PIL import Image, ImageDraw, ImageFont
import re

dark_fish_percentile = 3
fish_blur_sigmas = 1
centroid_median_span = 2

light_toggle_threshold = 10
abs_tail_delta_threshold = 20
abs_tail_delta_cap = 100
abs_tail_offset_threshold = 30

avg_position_bounds = (0.4, 0.85)

num_position_bins = 5

num_calibration_frames = 100

fnull = open(os.devnull, 'r+b')

def process_frame(img, tmp_img1, tmp_img2, tmp_img3, debug_frame_sink=None):
    """Process frame image, returning (brightness, tail_position) pair.

       img is RGB packed array with shape (H, W, 3) assumed to be
       grayscale data and MAY be destructively mutated by this
       processing.

       tmp_img1 and tmp_img2 are arrays of uint8 type and (H, W)
       shape used for intermediate calculations.

       tmp_imt3 is array of bool type and (H, W) shape used for
       intermediate calculations.

       debug_frame_sink must be a function accepting the same array
       input which will be modified to display debug information. A
       value of None (default) will skip production of debug data.

    """
    img_rgb = img
    img_g = img_rgb[:,:,0]
    H, W = img_g.shape

    img_max = tmp_img1
    img_dif = tmp_img2
    mask = tmp_img3

    max_window = 11
    mask_thresh = 12
    maximum_filter1d(img_g, max_window, 0, output=img_max)
    np.subtract(img_max, img_g, out=img_dif)
    np.greater(img_dif, mask_thresh, out=mask)

    img_brightness = int(np.sum(img_g) / ( W * H ))
    
    # find the "heights" i.e. centers of mass in Y axis of dark pixels
    x_heights = (np.nansum((mask * np.array(range(img_g.shape[0]))[:,None]), axis=0) // np.nansum(mask, axis=0))

    tail_length = np.nansum(x_heights > 0)

    tail_slc = slice( int(W*avg_position_bounds[0]), int(W*avg_position_bounds[1]) )
    tail_position = int(np.nan_to_num(np.nansum( x_heights[tail_slc] ) // np.nansum( x_heights[tail_slc] > 0 )))

    position_bins = []
    for b in range(num_position_bins):
        bin_slc = slice( int(W*b//num_position_bins), int(W*(b+1)//num_position_bins) )
        position_bins.append(
            int(np.nan_to_num(np.nansum( x_heights[bin_slc] ) // np.nansum( x_heights[bin_slc] > 0 )))
        )
    
    # illustrate the analysis decisions in an output movie frame
    if debug_frame_sink is not None:
        img_rgb[:,:,2] *= (np.uint8(1) - mask)
        img_rgb[:,:,2] += mask * np.uint8(255)
        for x in range(int(W*avg_position_bounds[0]), int(W*avg_position_bounds[1])):
            if x_heights[x] > 0:
                img_rgb[int(x_heights[x]), x, 0] = np.uint8(255)
        debug_frame_sink(img_rgb)
    
    return img_brightness, tail_position, position_bins, x_heights, tail_length

def main(moviename):
    try:
        m = re.match('^(?P<id>[^.]+)[.]m4v$', os.path.basename(moviename))
        movie_id = m.groupdict()['id']
    except:
        raise ValueError('Movie name "%s" should be in form "ID.m4v" with valid experiment identifier.' % moviename)

    # this produces a JSON metadata document about the movie on standard output
    probecmd = [
        'ffprobe',
        '-i', moviename,
        '-show_streams',
        '-of', 'json'
    ]

    # go ahead and get the movie metadata
    probe_pipe = subprocess.Popen(probecmd, stdin = fnull, stdout = subprocess.PIPE, bufsize=1024**2)
    probe_pipe.wait()
    doc = probe_pipe.stdout.read()
    del probe_pipe

    meta = json.loads(doc)
    del doc

    assert len(meta['streams']) == 1
    
    meta = meta['streams'][0]
    shape =  meta['height'], meta['width']
    nbframes = int(meta['nb_frames'])
    
    frate = meta['avg_frame_rate'].split('/')
    assert type(frate) is list
    assert len(frate) == 2
    frate = float(frate[0]) / float(frate[1])
    
    ffmpeg_loglevel = os.getenv('FISHSPY_LOGLEVEL', 'info')
    
    video_filters = []
    
    crop = os.getenv('FISHSPY_CROP')
    if crop:
        try:
            W, H, X, Y = map(lambda x: int(x), crop.split(':'))
            video_filters += [
                'crop=%s' % crop
            ]
            shape = H, W
        except:
            print ("Could not decode crop parameter. Expected width:height:xoffset:yoffset with decimal numbers.")
            raise

    frame_nbytes = shape[0] * shape[1] * 3

    gamma = os.getenv('FISHSPY_GAMMA')
    if gamma:
        gamma = float(gamma)

    contrast = os.getenv('FISHSPY_CONTRAST')
    if contrast:
        contrast = float(contrast)

    if gamma is not None or contrast is not None:
        if contrast is None:
            contrast = 1.0
        if gamma is None:
            gamma = 1.0
        
        video_filters += [
            'eq=%f:0.0:1.0:%f' % (contrast, gamma)
        ]

    if video_filters:
        video_filters = [
            '-vf', ','.join(video_filters)
        ]
        
    # this generates a stream of raw video pixels to standard output
    readcmd = [
        'ffmpeg',
        '-loglevel', ffmpeg_loglevel, '-stats' if ffmpeg_loglevel == 'info' else '-nostats',
        '-i', moviename
    ] + video_filters + [
        '-f', 'image2pipe', '-pix_fmt', 'rgb24',
        '-vcodec', 'rawvideo', '-'
    ]

    # this accepts a stream of raw video pixels on standard input
    writecmd = [
        'ffmpeg',
        '-loglevel', ffmpeg_loglevel, '-stats' if ffmpeg_loglevel == 'info' else '-nostats',
        '-y', # clobber
        '-f', 'rawvideo',
        '-s', '%dx%d' % (shape[1], shape[0]),
        '-pix_fmt', 'rgb24',
        '-r', meta['r_frame_rate'],
        '-i', '-',
        '-an',
        '-vcodec', 'libx264',
        '-pix_fmt', 'yuv420p',
        '-x264opts', 'crf=31:bframes=5',
        '%s.debug.m4v' % movie_id
    ]

    # setup the analysis output streams
    csvwriter1 = csv.writer(open('%s.events.csv' % movie_id, 'w'))
    csvwriter1.writerow( ('frameno','avg. brightness','avg. tailpos','avg. brightness delta','avg. tailpos delta','comment') )

    csvwriter2 = csv.writer(open('%s.frame_measures.csv' % movie_id, 'w'))
    csvwriter2.writerow( ('frameno','avg. brightness') + tuple([ 'position bin %d' % b for b in range(num_position_bins) ]) )

    if os.getenv('FISHSPY_HDF5', 'false').lower() == 'true':
        h5file = h5py.File('%s.frame_measures.hdf5' % movie_id, 'w')
        h5file.attrs['src_movie'] = moviename
        h5file.attrs['X'] = shape[1]
        h5file.attrs['Y'] = shape[0]
        h5file.attrs['nframes'] = nbframes
        h5d_brightness = h5file.create_dataset('brightness', (nbframes,), dtype=np.uint8, chunks=(min(nbframes,1000),), compression='gzip')
        h5d_x_heights = h5file.create_dataset('positions', (nbframes, shape[1]), dtype=np.uint16, chunks=(min(nbframes,1024), shape[1]), compression='gzip')
    else:
        h5file = None
        
    # setup the image buffer we'll use for each frame
    in_img = np.zeros(shape + (3,), dtype='uint8')
    in_buffer = memoryview(in_img)

    # start the input movie decoder
    in_pipe = subprocess.Popen(readcmd, stdin=fnull, stdout=subprocess.PIPE, bufsize=frame_nbytes*24)

    t = 0

    # arrays to collect calibration points
    idle_tail_positions = []
    idle_tail_lengths = []
    starting_brightness_levels = []

    # calibrated averages
    idle_tail_position = None
    idle_tail_length = None
    light_bases = None
    light_bases_last_frameno = None

    # iterative state tracking for event detection, debug output, etc.
    prev_frame = None
    prev_light_index = None
    
    brightness = None
    avg_position = None
    position_bins = None
    tail_length = None
    note = ''
    light_index = 0

    is_light_event = None
    light_cycle_cnt = 1

    font = ImageFont.truetype('FreeSans.ttf', 16)

    def debug_movie_sink(f):
        #out_pipe.stdin.write(f.tobytes())
        if brightness is not None:
            #f[avg_position,:,0] = 255
            #f[avg_position,:,1] = 0
            #f[avg_position,:,2] = 255
            img = toimage(f)
            draw = ImageDraw.Draw(img)
            tsec = t / frate
            tmin = int(tsec) / 60 % 60
            thour = int(tsec) / 60 / 60
            tsec = tsec % 60
            draw.text((0, 0), "Time: %.2d:%.2d:%04.1f" % (thour, tmin, tsec), (255,255,255), font=font)
            draw.text((0, 25), "Bright: %.3d" % brightness, (255,255,255), font=font)
            draw.text((0, 50), "Position: %.3d" % (avg_position,), (255,255,255), font=font)
            light_color = [
                (128,128,128),
                (0, 255, 0),
                (255, 0, 0)
            ][min(light_index,2)]
            draw.text(
                (0, 75),
                "Light state=%s event=%s" % (['off','CS','US'][min(light_index,2)], light_cycle_cnt),
                light_color,
                font=font
            )
            draw.text((0, 100), note, (255,255,255), font=font)
        else:
            img = toimage(f)
        out_pipe.stdin.write(img.tobytes())
    
    # conditionally start debug movie output encoder
    if os.getenv('DEBUG_MOVIE', 'false').lower() == 'true':
        out_pipe = subprocess.Popen(writecmd, stdin=subprocess.PIPE, bufsize=frame_nbytes*24)
        sink = debug_movie_sink
    else:
        out_pipe = None
        sink = None

    tmp_img1 = np.zeros(shape, dtype=np.uint8)
    tmp_img2 = np.zeros(shape, dtype=np.uint8)
    tmp_img3 = np.zeros(shape, dtype=np.bool)

    # process every input frame
    while t < nbframes:
        # get raw pixels from input decoder and stuff into image buffer
        in_pipe.stdout.readinto(in_buffer)

        brightness, avg_position, position_bins, x_heights, tail_length = process_frame(
            in_img,
            tmp_img1=tmp_img1,
            tmp_img2=tmp_img2,
            tmp_img3=tmp_img3,
            debug_frame_sink=sink
        )
        if h5file is not None:
            h5d_brightness[t] = brightness
            h5d_x_heights[t,:] = x_heights

        # build up a baseline idle tail position
        if t < num_calibration_frames:
            idle_tail_positions.append(avg_position)
            idle_tail_lengths.append(tail_length)
            starting_brightness_levels.append(brightness)
        elif t == num_calibration_frames:
            idle_tail_position = sum(idle_tail_positions) / num_calibration_frames
            idle_tail_length = sum(idle_tail_lengths) / num_calibration_frames
            light_bases = [ sum(starting_brightness_levels) / num_calibration_frames ]
            light_bases_last_frameno = t
            light_index = 0

        note = []
        is_light_event = False
        if t >= num_calibration_frames:
            # comparisons to baseline
            if float(tail_length) / idle_tail_length < 0.8:
                note.append('tail blur')

            if abs(avg_position - idle_tail_position) > abs_tail_offset_threshold:
                note.append('tail bent')

            if (brightness - light_bases[-1]) > light_toggle_threshold:
                if (t - light_bases_last_frameno) > 10:
                    # expand our set of light tiers, assumes monotonic ramp during discovery
                    light_bases.append(brightness)
                else:
                    # revise our still rising last tier
                    light_bases[-1] = brightness
                light_bases_last_frameno = t

            prev_light_index = light_index

            # rough fit our current light-index
            for light_index in range(len(light_bases)):
                mid = light_bases[light_index]
                if brightness < mid:
                    break
                if light_index < len(light_bases)-1:
                    high = light_bases[light_index+1]
                    if brightness < (mid + (high-mid) * 0.3):
                        break

            if prev_light_index != light_index:
                if light_index == 0:
                    if prev_light_index > 0:
                        light_cycle_cnt += 1
                    
                note.append('light state=%s cycle=%d' % (['off','CS','US'][min(light_index,2)], light_cycle_cnt))
                is_light_event = True
                    
        if prev_frame:
            # comparisons to previous frame
            if (abs(avg_position - prev_frame[2]) > abs_tail_delta_threshold):
                note.append('tail fast')

        note = ','.join(note)

        # conditionally log the frame results only on significant change
        if prev_frame:
            light_delta = brightness - prev_frame[1]
            pos_delta = avg_position - prev_frame[2]
            if (abs(pos_delta) > 1  and abs(pos_delta) < abs_tail_delta_cap) or is_light_event:
                csvwriter1.writerow((t, brightness, avg_position, light_delta, pos_delta, note))

        csvwriter2.writerow( (t, brightness) + tuple(position_bins) )
            
        prev_frame = (t, brightness, avg_position, note)
        t += 1

    if out_pipe:
        out_pipe.stdin.close()

    in_pipe.wait()
        
    if out_pipe:
        out_pipe.wait()

    if h5file is not None:
        h5file.close()
    
if __name__ == '__main__':
    moviename = sys.argv[1]
    exit(main(moviename))

